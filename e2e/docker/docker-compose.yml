version: "2"

services:
  master:
    #build: ./spark/
    #image: spark
    image: lateralthinking/spark
    command: spark-class org.apache.spark.deploy.master.Master -h master
    hostname: master
    environment:
      SPARK_CONF_DIR: /conf
    ports:
      - 7077:7077
      - 8080:8080
      - 50070:50070
    volumes:
      - ./conf/master:/conf
    volumes_from:
      - logfiles

  worker:
    #build: ./spark/
    #image: spark
    image: lateralthinking/spark
    command: spark-class org.apache.spark.deploy.worker.Worker spark://master:7077
    environment:
      SPARK_WORKER_CORES: 1
      SPARK_WORKER_MEMORY: 2g
      SPARK_CONF_DIR: /conf
    depends_on:
      - master
    volumes:
      - ./conf/worker:/conf
    volumes_from:
      - logfiles

  history:
    #build: ./spark/
    #image: spark
    image: lateralthinking/spark
    command: spark-class org.apache.spark.deploy.history.HistoryServer
    hostname: history
    environment:
      SPARK_CONF_DIR: /conf
    expose: 
      - 18080
    ports:
      - 18080:18080
    volumes:
      - ./conf/history:/conf
    volumes_from:
      - logfiles


  zookeeper:
    image: wurstmeister/zookeeper
    hostname: zookeeper
    ports:
      - 2181:2181

  kafka:
    image: wurstmeister/kafka
    depends_on:
      - zookeeper
    ports:
      - 9092
    environment:
      #KAFKA_ADVERTISED_HOST_NAME: 192.168.99.100
      HOSTNAME_COMMAND: "route -n | awk '/UG[ \t]/{print $$2}'"
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock

  logfiles:
    image: alpine
    volumes:
      - /tmp/spark-events